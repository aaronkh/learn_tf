{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple NN classifier\n",
    "## The most basic tensorflow example\n",
    "------\n",
    "Code used: [Basic classification](https://www.tensorflow.org/tutorials/keras/classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image above contains a 28 by 28 2D array of values between 0 and 255. The labels arrays contain a number representing a different category of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier labeling, initalize the category names\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# An example image\n",
    "plt.imshow(train_images[0])\n",
    "plt.title(class_names[train_labels[0]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the data by scaling it [0, 255] => [0, 1]\n",
    "# Question: What happens if we don't?\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), # Question: Why do we need to flatten?\n",
    "    keras.layers.Dense(128, activation='relu'), # Experiment with different activation functions!\n",
    "    keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`keras.Sequential` describes the model as as series of operations starting with the first array element. For our purposes, we'll use the following CNN model:\n",
    "1. Flatten: This layer transforms our 28x28 image into a single vector of length 28\\*28=784.\n",
    "2. Neural layer: This layer contains `128` neurons. It learns how to classify the image. \n",
    "3. Output layer: This layer contains 10 neurons to activate with one corresponding to each possible category.\n",
    "\n",
    "Note that the `dense` keyword for the last two layers mean that they are *densely connected* to each other (that is, they are fully connected). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to compile the model before we can use it. This method requires a loss function to be specified at the minimum, but we can also set other parameters as above. Above are the recommended parameters as provided by the TF tutorial, but feel free to experiment with others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.4984 - accuracy: 0.8246\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.3760 - accuracy: 0.8637\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.3355 - accuracy: 0.8773\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3096 - accuracy: 0.8861\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 8s 130us/sample - loss: 0.2933 - accuracy: 0.8912\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2785 - accuracy: 0.8976\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2659 - accuracy: 0.9018\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 151us/sample - loss: 0.2569 - accuracy: 0.9038\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 12s 196us/sample - loss: 0.2462 - accuracy: 0.9078\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 12s 195us/sample - loss: 0.2419 - accuracy: 0.9088\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty self-explanatory: given a training set and training labels, fit the model to the data. Defaults to 1 epoch (which obviously is not very accurate at all)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras includes the very handy `model.evaluate` method for testing the trained model against a test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.2528 - accuracy: 0.8760\n"
     ]
    }
   ],
   "source": [
    "# The verbose=2 parameter squelches other ouput other than loss and accuracy.\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a test accuracy that is lower than the training score, suggesting overfitting. \n",
    "\n",
    "In the future, we might consider adding a regularization parameter using the `kernel_regularizer` while building our model layers. Adding dropout to the model is also a valid approach to minimizing overfitting here. We can do this by adding a dropout layer before the output with `layers.Dropout(0.5)`.\n",
    "\n",
    "Of course, combining *both* approaches would usually lead to the best results, and Keras makes it easy to iteratively build our model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply call `model.predict` to get predictions. This method will return the results of the ouput layer (i.e. a list of porbabilities), so we call `np.argmax` to get the most likely one. \n",
    "\n",
    "Note that `keras` optimizes for *batch prediction*; `model.predict` expects and uses a **list of inputs** not a single data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.5213996e-10, 8.5948254e-12, 1.3900605e-11, 5.8819807e-12,\n",
       "       3.8728057e-10, 4.3336307e-03, 1.0762592e-08, 4.9579889e-03,\n",
       "       1.8381929e-08, 9.9070835e-01], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model = tf.keras.Sequential([model, \n",
    "                                         tf.keras.layers.Softmax()])\n",
    "predictions = probability_model.predict(test_images)\n",
    "predictions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's good practice to apply a final Softmax layer to scale the probabilities between 0 and 1. Calling `argmax` on the results will net the same output as not having the layer (but we don't add it onto our trained model as it messes with the outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out some of the test images below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69616ee6495f4c6da6554a004dd581be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='1', description='image'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets.widgets import interact\n",
    "\n",
    "@interact(image='1')\n",
    "def predict_and_display(image):\n",
    "    try:\n",
    "        i = int(image)\n",
    "        plt.imshow(test_images[i])\n",
    "        plt.title(f'This is a {class_names[np.argmax(predictions[i])]}')\n",
    "        plt.xlabel(f'Actually a {class_names[test_labels[i]]}')\n",
    "        print('Probabilities\\n'+'-'*22)\n",
    "        for j in range(len(class_names)):\n",
    "            print(f'{class_names[j]:<12}{str(round(predictions[i][j], 4)):>10}')\n",
    "    except ValueError:\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_tf",
   "language": "python",
   "name": "learn_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
