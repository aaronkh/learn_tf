{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrating Keras saving feature\n",
    "## Reusing models others (or you!) have trained\n",
    "------\n",
    "Code used: [Save and load](https://www.tensorflow.org/tutorials/keras/save_and_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the same dataset and model from the classify_digits notebook, also found in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will create a completely new model with the same structure \n",
    "# (useful for determining if loading is sucessful)\n",
    "def create_new_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Flatten(input_shape=(28, 28)), \n",
    "        keras.layers.Dense(128, activation='relu'), \n",
    "        keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model (see the classify_digits notebook)\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "train_images = train_images/255.0\n",
    "test_images = test_images/255.0\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)), \n",
    "    keras.layers.Dense(128, activation='relu'), \n",
    "    keras.layers.Dense(10)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checkpoints let you resume training. They\n",
    "* are created with the `ModelCheckpoint` callback at the end of each training epoch\n",
    "* usually use the `.ckpt` file extension\n",
    "* have their filenames appended with indexing data when they are created while training\n",
    "* don't usually include model data (unless `save_weights_only=False`) so they're smaller than entire models and useful for training the same model repeatedly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1156 - accuracy: 0.9562 - val_loss: 0.4563 - val_accuracy: 0.88700 - ETA: 0s - loss: 0.1157 - accuracy: \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1122 - accuracy: 0.9585 - val_loss: 0.4549 - val_accuracy: 0.8864\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.1101 - accuracy: 0.9590 - val_loss: 0.4459 - val_accuracy: 0.8894\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.1093 - accuracy: 0.9590 - val_loss: 0.4782 - val_accuracy: 0.8847\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.1076 - accuracy: 0.9602 - val_loss: 0.4650 - val_accuracy: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x251f9087278>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='checkpoints/checkpoint.ckpt', # Gets appened with indexing data later\n",
    "    save_weights_only=True) # Smaller checkpoint size, otherwise saves whole model\n",
    "\n",
    "model.fit(train_images, \n",
    "          train_labels,  \n",
    "          epochs=5,\n",
    "          validation_data=(test_images,test_labels),\n",
    "          callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike checkpoints, models include **full information** about both weights and structure. This makes them useful outside of saving your own work because they do not require users create their own models with the same architecture.     \n",
    "Tensorflow by default can export into 2 types of files:\n",
    "1. `SavedModel` - This format is best used within Tensorflow applications. However, it is newer (there may be compatibility issues with older versions of TF) and not as widely adopted by other libraries.    \n",
    "2. `HDF5` - This format is standardized and guaranteed to work with older versions of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\example_model\\assets\n",
      "INFO:tensorflow:Assets written to: models\\example_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Python runs into errors if a cross-platform path isn't created\n",
    "model.save(os.path.join('models', 'example_model'))\n",
    "# Ending the filepath with .h5 extension will create a HDF5 file\n",
    "model.save(os.path.join('models', 'example_model')) \n",
    "# Calling model.save_weights(filepath) will save weights only (which is almost equivalent to a checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the checkpoint we created above. Note that the new model we use must be the **exact same structure** as the checkpoint's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = create_new_model()\n",
    "ckpt = tf.train.Checkpoint(net=new_model)\n",
    "# When dealing with more than one checkpoint, consider using a CheckpointManager\n",
    "# ckpt_manager = tf.train.CheckpointManager(ckpt, 'checkpoints', max_to_keep = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/1 - 1s - loss: 0.1013 - accuracy: 0.9587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10999159338002404, 0.9586833]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.restore('checkpoints/checkpoint.ckpt'); # Loads the checkpoint from path\n",
    "model.evaluate(train_images,  train_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are easy to load: simply call `keras.models.load_model` and the appropriate weights and nodes will be loaded! Like the saving models, it takes both `SavedModel` and `HDF5` formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original model\n",
      "----------\n",
      "60000/1 - 2s - loss: 0.1013 - accuracy: 0.9587\n",
      "10000/1 - 0s - loss: 0.2362 - accuracy: 0.8857\n",
      "\n",
      "Loaded model\n",
      "----------\n",
      "60000/1 - 2s - loss: 0.1392 - accuracy: 0.9516\n",
      "10000/1 - 0s - loss: 0.2444 - accuracy: 0.8806\n",
      "\n",
      "Loaded model (HDF5) \n",
      "----------\n",
      "60000/1 - 2s - loss: 0.1392 - accuracy: 0.9516\n",
      "10000/1 - 0s - loss: 0.2444 - accuracy: 0.8806\n"
     ]
    }
   ],
   "source": [
    "loaded_model = keras.models.load_model(os.path.join('models', 'example_model'))\n",
    "loaded_model_h5 = keras.models.load_model(os.path.join('models', 'example_model.h5'))\n",
    "print('\\nOriginal model\\n' + '-'*10)\n",
    "model.evaluate(train_images,  train_labels, verbose=2)\n",
    "model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nLoaded model\\n' + '-'*10)\n",
    "loaded_model.evaluate(train_images,  train_labels, verbose=2)\n",
    "loaded_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('\\nLoaded model (HDF5) \\n' + '-'*10)\n",
    "loaded_model_h5.evaluate(train_images,  train_labels, verbose=2);\n",
    "loaded_model_h5.evaluate(test_images,  test_labels, verbose=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expectedly, the loaded models yield exactly the same results as the original model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Footnotes:\n",
    "* In some documentation, the author refers to a class called `Saver`. This has been removed and its functionality ported to `Checkpoint` in Tensorflow 2.0+."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_tf",
   "language": "python",
   "name": "learn_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
